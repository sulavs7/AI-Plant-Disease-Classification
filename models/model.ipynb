{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "eb8418af",
      "metadata": {
        "id": "eb8418af"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets,transforms,models\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bd2cba7",
      "metadata": {
        "id": "9bd2cba7"
      },
      "source": [
        "Device Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c2b23022",
      "metadata": {
        "id": "c2b23022",
        "outputId": "a9f233ae-f67c-43c6-ffae-7b66fa4fe9b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "21cb171d",
      "metadata": {
        "id": "21cb171d"
      },
      "outputs": [],
      "source": [
        "train_dir = '/content/drive/MyDrive/plant_village_updated/plant_village_updated/train'\n",
        "test_dir = '/content/drive/MyDrive/plant_village_updated/plant_village_updated/test'\n",
        "val_dir = '/content/drive/MyDrive/plant_village_updated/plant_village_updated/val'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dd2218a",
      "metadata": {
        "id": "9dd2218a"
      },
      "source": [
        "Transforming the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "8165f04e",
      "metadata": {
        "id": "8165f04e"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4b727e5",
      "metadata": {
        "id": "a4b727e5"
      },
      "source": [
        "Loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "c1a88da9",
      "metadata": {
        "id": "c1a88da9"
      },
      "outputs": [],
      "source": [
        "train_dataset = datasets.ImageFolder(train_dir,transform=transform)\n",
        "val_dataset = datasets.ImageFolder(val_dir,transform=transform)\n",
        "test_dataset = datasets.ImageFolder(test_dir,transform=transform)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de5f4cee",
      "metadata": {
        "id": "de5f4cee"
      },
      "source": [
        "Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "1d20dcc3",
      "metadata": {
        "id": "1d20dcc3"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "lr=1e-4"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70e76470",
      "metadata": {
        "id": "70e76470"
      },
      "source": [
        "Making Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "e4f5cfd0",
      "metadata": {
        "id": "e4f5cfd0",
        "outputId": "9aba3dc6-a549-4dd2-bdd2-3533b2bdfdcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "val_dataloader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=4,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=4,\n",
        "    pin_memory=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a21f0d06",
      "metadata": {
        "id": "a21f0d06",
        "outputId": "268ea605-1d1c-4d49-cc43-65e715fdc15d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\DiseaseClassification\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 3, 224, 224])\n",
            "tensor([25, 20,  8,  2,  3, 26, 23, 16,  5, 20, 11, 11,  1,  3, 14, 27, 21, 15,\n",
            "        28, 15,  1, 14,  6,  6,  9,  0,  9, 14, 12,  1, 22, 10])\n"
          ]
        }
      ],
      "source": [
        "for train_images,_ in train_dataloader:\n",
        "    print(train_images.shape)\n",
        "    print(_)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3eef37fc",
      "metadata": {
        "id": "3eef37fc"
      },
      "source": [
        "Model Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "1325dff0",
      "metadata": {
        "id": "1325dff0",
        "outputId": "d80a9d81-2589-4f75-cbcc-4a0ffe849cfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 192MB/s]\n"
          ]
        }
      ],
      "source": [
        "model = models.resnet50(pretrained=True)\n",
        "num_classes = len(train_dataset.classes)\n",
        "model.fc = nn.Linear(model.fc.in_features,num_classes) #to make the model to have the same no of class as i want"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81492b95",
      "metadata": {
        "id": "81492b95"
      },
      "source": [
        "Training Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "7b4a8a45",
      "metadata": {
        "id": "7b4a8a45"
      },
      "outputs": [],
      "source": [
        "n_epoch = 10\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "model = model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "80327bd8",
      "metadata": {
        "id": "80327bd8"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = './checkpoints'\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "0fcc70d3",
      "metadata": {
        "id": "0fcc70d3"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(state, filename):\n",
        "    torch.save(state, filename)\n",
        "\n",
        "def load_checkpoint(filepath, model, optimizer):\n",
        "    checkpoint = torch.load(filepath)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    start_epoch = checkpoint['epoch'] + 1\n",
        "    print(f\"Checkpoint loaded: epoch {checkpoint['epoch']}\")\n",
        "    return start_epoch\n",
        "\n",
        "# Try to load checkpoint if exists (set your checkpoint path)\n",
        "start_epoch = 1\n",
        "checkpoint_path = os.path.join(checkpoint_dir, 'best_model.pth')\n",
        "if os.path.isfile(checkpoint_path):\n",
        "    start_epoch = load_checkpoint(checkpoint_path, model, optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "40535205",
      "metadata": {
        "id": "40535205"
      },
      "outputs": [],
      "source": [
        "def train_one_step(model, criterion, optimizer, images, labels):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    correct = (preds == labels).sum().item()\n",
        "    return loss.item(), correct\n",
        "\n",
        "def val_one_step(model, criterion, images, labels):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct = (preds == labels).sum().item()\n",
        "    return loss.item(), correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "e2230cce",
      "metadata": {
        "id": "e2230cce",
        "outputId": "514e456f-0a9a-481c-b5ca-8da773737f9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining Epoch 1/10:   0%|          | 0/1678 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'float' object has no attribute 'item'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-963285984.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mtrain_epoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mtrain_epoch_correct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mtotal_train\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'item'"
          ]
        }
      ],
      "source": [
        "patience = 5\n",
        "best_val_acc = 0\n",
        "epochs_no_improve = 0\n",
        "\n",
        "for epoch in range(start_epoch, n_epoch + 1):\n",
        "    train_epoch_loss = 0\n",
        "    train_epoch_correct = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for images, labels in tqdm(train_dataloader, desc=f'Training Epoch {epoch}/{n_epoch}'):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        loss, correct = train_one_step(model, criterion, optimizer, images, labels)\n",
        "        batch_size = images.size(0)\n",
        "\n",
        "        train_epoch_loss += loss * batch_size\n",
        "        train_epoch_correct += correct\n",
        "        total_train += batch_size\n",
        "\n",
        "    train_epoch_loss /= total_train\n",
        "    epoch_train_acc = train_epoch_correct / total_train\n",
        "\n",
        "    val_epoch_loss = 0\n",
        "    val_epoch_correct = 0\n",
        "    total_val = 0\n",
        "\n",
        "    for images, labels in tqdm(val_dataloader, desc=f'Validation Epoch {epoch}/{n_epoch}'):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        loss, correct = val_one_step(model, criterion, images, labels)\n",
        "        batch_size = images.size(0)\n",
        "\n",
        "        val_epoch_loss += loss * batch_size\n",
        "        val_epoch_correct += correct\n",
        "        total_val += batch_size\n",
        "\n",
        "    val_epoch_loss /= total_val\n",
        "    epoch_val_acc = val_epoch_correct / total_val\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f\"Epoch {epoch}: Train Loss: {train_epoch_loss:.4f}, Train Acc: {epoch_train_acc:.4f}\")\n",
        "    print(f\"Epoch {epoch}: Val Loss: {val_epoch_loss:.4f}, Val Acc: {epoch_val_acc:.4f}\")\n",
        "\n",
        "    # Early Stopping Logic\n",
        "    if epoch_val_acc > best_val_acc:\n",
        "        best_val_acc = epoch_val_acc\n",
        "        epochs_no_improve = 0\n",
        "\n",
        "        # Save the best model checkpoint\n",
        "        checkpoint = {\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'train_loss': train_epoch_loss,\n",
        "            'val_loss': val_epoch_loss,\n",
        "            'train_acc': epoch_train_acc,\n",
        "            'val_acc': epoch_val_acc,\n",
        "        }\n",
        "        best_model_path = os.path.join(checkpoint_dir, 'best_model.pth')\n",
        "        save_checkpoint(checkpoint, best_model_path)\n",
        "        print(f\"Best model saved at epoch {epoch} with val acc: {best_val_acc:.4f}\")\n",
        "\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        print(f\"No improvement in val acc for {epochs_no_improve} epochs.\")\n",
        "\n",
        "    if epochs_no_improve >= patience:\n",
        "        print(f\"Early stopping triggered after {patience} epochs with no improvement.\")\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de2241ce",
      "metadata": {
        "id": "de2241ce"
      },
      "source": [
        "## Training Curve\n",
        "\n",
        "> Add blockquote\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "\n",
        "# Recreate the same model architecture\n",
        "model = models.resnet50(pretrained=False)  # No need for pretrained now\n",
        "num_classes = len(train_dataset.classes)\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "# Load the best checkpoint\n",
        "checkpoint = torch.load(\"/content/checkpoints/best_model.pth\", map_location=device)\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(f\"Loaded model from epoch {checkpoint['epoch']} with val_acc={checkpoint['val_acc']:.4f}\")\n"
      ],
      "metadata": {
        "id": "6B87n0eETCv7",
        "outputId": "e55e8306-fc5a-4ac7-d1de-ed0f9a63fe53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "6B87n0eETCv7",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model from epoch 10 with val_acc=0.9993\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Accuracy\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(train_acc, 'r.-', label='Train Accuracy')\n",
        "plt.plot(val_acc, 'g.-', label='Validation Accuracy')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training vs Validation Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Loss\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(train_loss, 'r.-', label='Train Loss')\n",
        "plt.plot(val_loss, 'g.-', label='Validation Loss')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Cross Entropy Loss\")\n",
        "plt.title(\"Training vs Validation Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Aoi-J3KeSZVU",
        "outputId": "ce47eb03-6fd6-44cc-888d-b714867e7280",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "id": "Aoi-J3KeSZVU",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_acc' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-533439095.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r.-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'g.-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_acc' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aZ33pFWETM_G",
        "outputId": "a7f4595b-64bd-43d9-c5ee-8bd6551d9769",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "id": "aZ33pFWETM_G",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'evaluate' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1796915629.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test Accuracy: {test_accuracy*100:.2f}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'evaluate' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "953b64b9",
      "metadata": {
        "id": "953b64b9",
        "outputId": "d2ed1686-4596-44a7-ee93-5624835cb7c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_acc' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2204808759.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r.-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'g.-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_acc' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Accuracy\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(train_acc, 'r.-', label='Train Accuracy')\n",
        "plt.plot(val_acc, 'g.-', label='Validation Accuracy')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Training vs Validation Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7ac598e",
      "metadata": {
        "id": "b7ac598e"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.plot(train_loss, 'r.-')\n",
        "plt.plot(val_loss, 'g.-')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel('Cross Entropy Loss')\n",
        "plt.title(\"Training Loss\")\n",
        "plt.legend(['Training Loss', 'Validation Loss'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ce7070e",
      "metadata": {
        "id": "4ce7070e"
      },
      "source": [
        "## Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8de58c9",
      "metadata": {
        "id": "e8de58c9"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, test_dataloader):\n",
        "    model.eval()\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for test_images, test_labels in tqdm(test_dataloader, desc=\"Evaluating\"):\n",
        "        test_images = test_images.to(device)\n",
        "        test_labels = test_labels.to(device)\n",
        "\n",
        "        outputs = model(test_images)  # shape: (batch_size, num_classes)\n",
        "        _, preds = torch.max(outputs, 1)  # predicted class indices\n",
        "        total_correct += (preds == test_labels).sum().item()\n",
        "        total_samples += test_labels.size(0)\n",
        "\n",
        "    accuracy = total_correct / total_samples\n",
        "    return accuracy\n",
        "\n",
        "print(\"Accuracy of model on test dataset: \", evaluate(model, test_dataloader))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}